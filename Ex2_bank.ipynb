{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import openml\n",
    "#our neural network\n",
    "from neuralnetwork import Network,FCLayer,ActivationLayer,sigmoid,sigmoid_prime,tanh,tanh_prime,categorical_cross_entropy,categorical_cross_entropy_prime,mse,mse_prime,binary_cross_entropy,binary_cross_entropy_prime,relu,relu_prime\n",
    "import time\n",
    "#sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import recall_score,accuracy_score,confusion_matrix, ConfusionMatrixDisplay, precision_score, make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV,KFold,cross_val_score\n",
    "import itertools\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from neuralnetwork import Network,FCLayer,ActivationLayer\n",
    "from neuralnetwork import sigmoid,sigmoid_prime,tanh,tanh_prime,categorical_cross_entropy,categorical_cross_entropy_prime,mse,mse_prime,softmax,softmax_prime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directly downloading from openml\n",
    "dataset = openml.datasets.get_dataset(1461)\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "    dataset_format=\"dataframe\", target=dataset.default_target_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank = pd.DataFrame(X, columns=attribute_names)\n",
    "df_bank[\"class\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "column_names_bank = ['age', 'job', 'marital', 'education', 'default',\n",
    "                     'balance', 'housing', 'loan', 'contact', 'day',\n",
    "                     'month', 'duration', 'campaign', 'pdays',\n",
    "                     'previous', 'poutcome', 'class']\n",
    "df_bank.columns = column_names_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no   2143.0     yes   no   \n",
       "1   44    technician   single  secondary      no     29.0     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no      2.0     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no   1506.0     yes   no   \n",
       "4   33       unknown   single    unknown      no      1.0      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome class  \n",
       "0  unknown    5   may     261.0         1   -1.0       0.0  unknown     1  \n",
       "1  unknown    5   may     151.0         1   -1.0       0.0  unknown     1  \n",
       "2  unknown    5   may      76.0         1   -1.0       0.0  unknown     1  \n",
       "3  unknown    5   may      92.0         1   -1.0       0.0  unknown     1  \n",
       "4  unknown    5   may     198.0         1   -1.0       0.0  unknown     1  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#some jobs look like can be combined together into same category\n",
    "df_bank['job'] = df_bank['job'].replace(['services','housemaid'], 'pink-collar')\n",
    "df_bank['job'] = df_bank['job'].replace(['admin','management'], 'blue-collar')\n",
    "df_bank['job'] = df_bank['job'].replace(['student','unemployed','retired'], 'other')\n",
    "\n",
    "#dropping this column since it does not bring much value to our analysis\n",
    "df_bank.drop('contact', axis=1, inplace=True)\n",
    "\n",
    "#dropping these columns since they do not bring much value to our analysis\n",
    "df_bank.drop('month', axis=1, inplace=True)\n",
    "df_bank.drop('day', axis=1, inplace=True)\n",
    "\n",
    "# Replacing 'other' with unknown since for both of them we do not have valuable information\n",
    "df_bank['poutcome'] = df_bank['poutcome'].replace('other', 'unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bank.drop(['class'], axis=1)[['job','marital','education','default','balance','housing','loan','poutcome','age','balance','duration','pdays','previous']]\n",
    "Y = df_bank['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['job','marital','education','default','housing','loan','poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Perform integer encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    X[col] = label_encoder.fit_transform(X[col])\n",
    "X = X.to_numpy()\n",
    "\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "y_reshaped = Y.to_numpy().reshape(-1,1)\n",
    "Y = encoder.fit_transform(y_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1234)\n",
    "\n",
    "#splitting into train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1,random_state = 1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data\n",
    "\n",
    "Since some of the features are categorical, we will apply scaling to the numeric columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[len(cat_cols):] = scaler.fit_transform(X_train[len(cat_cols):])\n",
    "X_test[len(cat_cols):]  = scaler.transform(X_test[len(cat_cols):])\n",
    "X_val[len(cat_cols):]  = scaler.transform(X_val[len(cat_cols):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m      8\u001b[0m net\u001b[38;5;241m.\u001b[39muse(binary_cross_entropy, binary_cross_entropy_prime)\n\u001b[0;32m---> 10\u001b[0m err_vect \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m net\u001b[38;5;241m.\u001b[39mplot_error_curve(err_vect)\n",
      "File \u001b[0;32m~/Desktop/TUSS23/ML/Exercise 2/MachineLearningEx2/neuralnetwork.py:119\u001b[0m, in \u001b[0;36mNetwork.fit\u001b[0;34m(self, x_train, y_train, epochs, learning_rate)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/nadia/Desktop/TUSS23/ML/Exercise%202/MachineLearningEx2/neuralnetwork.py?line=115'>116</a>\u001b[0m err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(y_train[j], output)\n\u001b[1;32m    <a href='file:///Users/nadia/Desktop/TUSS23/ML/Exercise%202/MachineLearningEx2/neuralnetwork.py?line=117'>118</a>\u001b[0m \u001b[39m# backward propagation\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/nadia/Desktop/TUSS23/ML/Exercise%202/MachineLearningEx2/neuralnetwork.py?line=118'>119</a>\u001b[0m error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_prime(y_train[j], output)\n\u001b[1;32m    <a href='file:///Users/nadia/Desktop/TUSS23/ML/Exercise%202/MachineLearningEx2/neuralnetwork.py?line=119'>120</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[1;32m    <a href='file:///Users/nadia/Desktop/TUSS23/ML/Exercise%202/MachineLearningEx2/neuralnetwork.py?line=120'>121</a>\u001b[0m     error \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mbackward_propagation(error, learning_rate)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 1234\n",
    "# network with 2 layers\n",
    "net = Network()\n",
    "net.add(FCLayer(13, 2,seed =  1234))  \n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "\n",
    "# train\n",
    "net.use(binary_cross_entropy, binary_cross_entropy_prime)\n",
    "\n",
    "err_vect = net.fit(X_train, y_train, epochs=500, learning_rate=0.1)\n",
    "net.plot_error_curve(err_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
